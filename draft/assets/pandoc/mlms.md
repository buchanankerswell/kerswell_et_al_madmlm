| Model               | Advantages                                                         | Disadvantages                                                |
|---------------------|--------------------------------------------------------------------|--------------------------------------------------------------|
| Decision Tree       | Simple and easy to interpret                                       | Tends to overfit the training data and lack generalization   |
| Random Forest       | Robust to overfitting and requires little feature engineering      | Lack of interpretability                                     |
| K Nearest           | Simple and easy to implement                                       | Sensitive to the choice of k                                 |
| Neural Network 1L   | Fast training and prediction                                       | Limited representation power compared to deeper networks     |
| Neural Network 2L   | More expressive than single-layer networks                         | Prone to overfitting when the network is too complex         |
| Neural Network 3L   | Higher representation power and capacity to learn complex patterns | Training can be computationally expensive for large datasets |
